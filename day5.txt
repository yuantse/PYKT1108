import numpy as np
from tensorflow import nn

scores = [3.0, 1.0, 2.0]


def normalRatio(x):
    x = np.array(x)
    return x / np.sum(x)


def mySoftMax(x):
    x = np.array(x)
    return np.exp(x) / np.sum(np.exp(x))


print(normalRatio(scores))
print(mySoftMax(scores))
print(nn.softmax(scores).numpy())
~~~~~~~~~~~~~~~~~~~~~
# 1000 OK
# 10000 upper
y = 1000


def calculate(x):
    for i in range(0, 1000000):
        x += 0.0000001
    x -= 0.1
    return x


print('result=%.6f' % calculate(y))
~~~~~~~~~~~~~~~~~~~~
from matplotlib import pyplot as plt
import tensorflow as tf
import keras
import numpy

(train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data()
print("image shape", train_images.shape, test_images.shape)
print("label shape", train_labels.shape, test_labels.shape)
print(numpy.unique(train_labels, return_counts=True))
print(numpy.unique(test_labels, return_counts=True))


def plotImage(index):
    plt.title("the image is %d" % train_labels[index])
    plt.imshow(train_images[index], cmap='binary')
    plt.show()

plotImage(10005)

def plotTestImage(index):
    plt.title("the test image is %d"%test_labels[index])
    plt.imshow(test_images[index])
    plt.show()

plotTestImage(3000)
~~~~~~~~~~~~~~~~~~~~~
from keras.utils import np_utils

orig = [4, 6, 8]
NUM_DIGITS = 15

for o in orig:
    print("orig={}, shift={}".format(o, np_utils.to_categorical(o, NUM_DIGITS)))

~~~~~~~~~~~~~~~~~~~~
# import keras
import tensorflow as tf
import numpy as np

(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()

FLATTEN_DIM = 28 * 28
TRAINING_SIZE = len(train_images)
TEST_SIZE = len(test_images)

trainImages = np.reshape(train_images, (TRAINING_SIZE, FLATTEN_DIM))
testImages = np.reshape(test_images, (TEST_SIZE, FLATTEN_DIM))
print(type(trainImages[0]), trainImages.shape, trainImages[0].shape)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
import tensorflow as tf
import keras
import numpy as np

(train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data()
#(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()

FLATTEN_DIM = 28 * 28
TRAINING_SIZE = len(train_images)
TEST_SIZE = len(test_images)

trainImages = np.reshape(train_images, (TRAINING_SIZE, FLATTEN_DIM))
testImages = np.reshape(test_images, (TEST_SIZE, FLATTEN_DIM))
print(type(trainImages[0]), trainImages.shape, trainImages[0].shape)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
import tensorflow as tf
import keras
import numpy as np
from keras import layers, models

(train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data()
# (train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()

FLATTEN_DIM = 28 * 28
TRAINING_SIZE = len(train_images)
TEST_SIZE = len(test_images)

trainImages = np.reshape(train_images, (TRAINING_SIZE, FLATTEN_DIM))
testImages = np.reshape(test_images, (TEST_SIZE, FLATTEN_DIM))
print(type(trainImages[0]), trainImages.shape, trainImages[0].shape)

trainImages = trainImages.astype(np.float32)
testImages = testImages.astype(np.float32)
trainImages /= 255
testImages /= 255
print(trainImages[0])

NUM_DIGITS = 10
trainLabels = keras.utils.np_utils.to_categorical(train_labels, NUM_DIGITS)
testLabels = keras.utils.np_utils.to_categorical(test_labels, NUM_DIGITS)
print(trainLabels[:5])

model = models.Sequential()
model.add(layers.Dense(128, activation=tf.nn.relu, input_shape=(FLATTEN_DIM,)))
model.add(layers.Dense(10, activation=tf.nn.softmax))
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
model.summary()
model.fit(trainImages, trainLabels, epochs=20)
~~~~~~~~~~~~~~~~~~~~~~~~
import tensorflow as tf
import keras
import numpy as np
from keras import layers, models

(train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data()
# (train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()

FLATTEN_DIM = 28 * 28
TRAINING_SIZE = len(train_images)
TEST_SIZE = len(test_images)

trainImages = np.reshape(train_images, (TRAINING_SIZE, FLATTEN_DIM))
testImages = np.reshape(test_images, (TEST_SIZE, FLATTEN_DIM))
print(type(trainImages[0]), trainImages.shape, trainImages[0].shape)

trainImages = trainImages.astype(np.float32)
testImages = testImages.astype(np.float32)
trainImages /= 255
testImages /= 255
print(trainImages[0])

NUM_DIGITS = 10
trainLabels = keras.utils.np_utils.to_categorical(train_labels, NUM_DIGITS)
testLabels = keras.utils.np_utils.to_categorical(test_labels, NUM_DIGITS)
print(trainLabels[:5])

model = models.Sequential()
model.add(layers.Dense(128, activation=tf.nn.relu, input_shape=(FLATTEN_DIM,)))
model.add(layers.Dense(10, activation=tf.nn.softmax))
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
model.summary()
board = keras.callbacks.TensorBoard(log_dir='logs/demo71/', histogram_freq=0,
                                    write_graph=True, write_images=True)
model.fit(trainImages, trainLabels, epochs=20, callbacks=[board])

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
tensorboard --logdir=logs
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
jupyter-notebook
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
import tensorflow as tf
import keras
import numpy as np
from keras import layers, models

(train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data()
# (train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()

FLATTEN_DIM = 28 * 28
TRAINING_SIZE = len(train_images)
TEST_SIZE = len(test_images)

trainImages = np.reshape(train_images, (TRAINING_SIZE, FLATTEN_DIM))
testImages = np.reshape(test_images, (TEST_SIZE, FLATTEN_DIM))
print(type(trainImages[0]), trainImages.shape, trainImages[0].shape)

origImage = trainImages[0]
trainImages = trainImages.astype(np.float32)
testImages = testImages.astype(np.float32)
trainImages /= 255
testImages /= 255
print(trainImages[0])
newImage = trainImages[0]

NUM_DIGITS = 10
trainLabels = keras.utils.np_utils.to_categorical(train_labels, NUM_DIGITS)
testLabels = keras.utils.np_utils.to_categorical(test_labels, NUM_DIGITS)
print(trainLabels[:5])

model = models.Sequential()
model.add(layers.Dense(128, activation=tf.nn.relu, input_shape=(FLATTEN_DIM,)))
model.add(layers.Dense(10, activation=tf.nn.softmax))
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
model.summary()
board = keras.callbacks.TensorBoard(log_dir='logs/demo71/', histogram_freq=0,
                                    write_graph=True, write_images=True)
model.fit(trainImages, trainLabels, epochs=20, callbacks=[board])

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
predictResult = model.predict(testImages)
predictResult[:5]
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
predict = np.argmax(predictResult, axis=-1)
predict[:5]
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
loss, accuracy = model.evaluate(testImages, testLabels)
loss, accuracy
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
from matplotlib import pyplot as plt
def plotTestImage(index):
    plt.title("the test image is %d"%test_labels[index])
    plt.imshow(test_images[index])
    plt.show()
plotTestImage(5)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
trainHistory = model.fit(trainImages, trainLabels, epochs=20, validation_split=0.1)

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
plt.plot(trainHistory.history['accuracy'],color='red')
plt.plot(trainHistory.history['val_accuracy'], color='green')
plt.legend(['training', 'validation'])
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
import pandas as pd
pd.crosstab(test_labels, predict, rownames=['label'], colnames=['predict'])
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
measure1 = pd.DataFrame({'label':test_labels, 'predict':predict})
measure1[:20]
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# depend on your result
measure1[(measure1.label==7) & (measure1.predict==2)]
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# depend on your result
error_2_7 = measure1[(measure1.label==7) & (measure1.predict==2)]
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
print(error_2_7.index)
for i in error_2_7.index:
    plotTestImage(i)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


import tensorflow as tf
import keras
from keras import datasets
from matplotlib import pyplot as plt

(train_images, train_labels,), (test_images, test_labels) = datasets.fashion_mnist.load_data()
class_names = ['T-shirt', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']
plt.imshow(train_images[0])
plt.colorbar()
plt.grid(False)
plt.show()
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
import tensorflow as tf
import keras
from keras import datasets
from matplotlib import pyplot as plt

(train_images, train_labels,), (test_images, test_labels) = datasets.fashion_mnist.load_data()
class_names = ['T-shirt', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']
# plt.imshow(train_images[0])
# plt.colorbar()
# plt.grid(False)
# plt.show()
print(train_images[0])
train_images = train_images / 255.0
test_images = test_images / 255.0
OFFSET = 0
plt.figure(figsize=(10, 8))
for i in range(25):
    plt.subplot(5, 5, i + 1)
    plt.xticks([])
    plt.yticks([])
    plt.imshow(train_images[i + OFFSET], cmap=plt.cm.binary)
    plt.xlabel(class_names[train_labels[i + OFFSET]])
plt.show()
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
import tensorflow as tf
import keras
from keras import datasets
from matplotlib import pyplot as plt
from keras.layers import Dense, Flatten
import numpy

(train_images, train_labels,), (test_images, test_labels) = datasets.fashion_mnist.load_data()
class_names = ['T-shirt', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']
print(numpy.unique(train_labels, return_counts=True))
# plt.imshow(train_images[0])
# plt.colorbar()
# plt.grid(False)
# plt.show()
print(train_images[0])
train_images = train_images / 255.0
test_images = test_images / 255.0
OFFSET = 0
plt.figure(figsize=(10, 8))
for i in range(25):
    plt.subplot(5, 5, i + 1)
    plt.xticks([])
    plt.yticks([])
    plt.imshow(train_images[i + OFFSET], cmap=plt.cm.binary)
    plt.xlabel(class_names[train_labels[i + OFFSET]])
plt.show()

layers = [Flatten(input_shape=(28, 28)),
          Dense(128, activation='relu'),
          Dense(64, activation='relu'),
          Dense(10, activation='softmax')]
model = keras.Sequential(layers)
model.summary()
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
model.fit(train_images, train_labels, epochs=10)
test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
import tensorflow as tf
import keras
from keras import datasets
from matplotlib import pyplot as plt
from keras.layers import Dense, Flatten
import numpy

(train_images, train_labels,), (test_images, test_labels) = datasets.fashion_mnist.load_data()
class_names = ['T-shirt', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']
print(numpy.unique(train_labels, return_counts=True))
# plt.imshow(train_images[0])
# plt.colorbar()
# plt.grid(False)
# plt.show()
print(train_images[0])
train_images = train_images / 255.0
test_images = test_images / 255.0
# OFFSET = 0
# plt.figure(figsize=(10, 8))
# for i in range(25):
#     plt.subplot(5, 5, i + 1)
#     plt.xticks([])
#     plt.yticks([])
#     plt.imshow(train_images[i + OFFSET], cmap=plt.cm.binary)
#     plt.xlabel(class_names[train_labels[i + OFFSET]])
# plt.show()

layers = [Flatten(input_shape=(28, 28)),
          Dense(128, activation='relu'),
          Dense(64, activation='relu'),
          Dense(10, activation='softmax')]
model = keras.Sequential(layers)
model.summary()
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
model.fit(train_images, train_labels, epochs=1)
test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)

num_rows = 5
num_cols = 3
num_images = num_rows * num_cols

import numpy as np


def plot_image(i, predictions_array, true_label, image):
    true_label = true_label[i]
    image = image[i]
    plt.grid(False)
    plt.xticks([])
    plt.yticks([])
    plt.imshow(image, cmap=plt.cm.binary)
    predicted_label = np.argmax(predictions_array)
    if predicted_label == true_label:
        color = 'blue'
    else:
        color = 'red'
    plt.xlabel("{} {:2.0f}% ({})".format(class_names[predicted_label],
                                         100 * np.max(predictions_array),
                                         class_names[true_label]), color=color)


def plot_value_array(i, predictions_array, true_label):
    pass


predictions = model.predict(test_images)
plt.figure(figsize=(2 * 2 * num_cols, 2 * num_rows))
for i in range(num_images):
    plt.subplot(num_rows, 2 * num_cols, 2 * i + 1)
    plot_image(i, predictions[i], test_labels, test_images)
    plt.subplot(num_rows, 2 * num_cols, 2 * i + 2)
plt.tight_layout()
plt.show()
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
import tensorflow as tf
import keras
from keras import datasets
from matplotlib import pyplot as plt
from keras.layers import Dense, Flatten
import numpy

(train_images, train_labels,), (test_images, test_labels) = datasets.fashion_mnist.load_data()
class_names = ['T-shirt', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']
print(numpy.unique(train_labels, return_counts=True))
# plt.imshow(train_images[0])
# plt.colorbar()
# plt.grid(False)
# plt.show()
print(train_images[0])
train_images = train_images / 255.0
test_images = test_images / 255.0
# OFFSET = 0
# plt.figure(figsize=(10, 8))
# for i in range(25):
#     plt.subplot(5, 5, i + 1)
#     plt.xticks([])
#     plt.yticks([])
#     plt.imshow(train_images[i + OFFSET], cmap=plt.cm.binary)
#     plt.xlabel(class_names[train_labels[i + OFFSET]])
# plt.show()

layers = [Flatten(input_shape=(28, 28)),
          Dense(128, activation='relu'),
          Dense(64, activation='relu'),
          Dense(10, activation='softmax')]
model = keras.Sequential(layers)
model.summary()
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
model.fit(train_images, train_labels, epochs=1)
test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)

num_rows = 5
num_cols = 3
num_images = num_rows * num_cols

import numpy as np


def plot_image(i, predictions_array, true_label, image):
    true_label = true_label[i]
    image = image[i]
    plt.grid(False)
    plt.xticks([])
    plt.yticks([])
    plt.imshow(image, cmap=plt.cm.binary)
    predicted_label = np.argmax(predictions_array)
    if predicted_label == true_label:
        color = 'blue'
    else:
        color = 'red'
    plt.xlabel("{} {:2.0f}% ({})".format(class_names[predicted_label],
                                         100 * np.max(predictions_array),
                                         class_names[true_label]), color=color)


def plot_value_array(i, predictions_array, true_label):
    true_label = true_label[i]
    plt.grid(False)
    plt.xticks(range(10))
    plt.yticks([])
    thisPlot = plt.bar(range(10), predictions_array, color='#888888')
    plt.ylim([0, 1])
    predicted_label = np.argmax(predictions_array)
    thisPlot[predicted_label].set_color('red')
    thisPlot[true_label].set_color('blue')
    pass


predictions = model.predict(test_images)
plt.figure(figsize=(2 * 2 * num_cols, 2 * num_rows))
for i in range(num_images):
    plt.subplot(num_rows, 2 * num_cols, 2 * i + 1)
    plot_image(i, predictions[i], test_labels, test_images)
    plt.subplot(num_rows, 2 * num_cols, 2 * i + 2)
    plot_value_array(i, predictions[i], test_labels)
plt.tight_layout()
plt.show()
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
demo73

import random


def calculateBMI(height, weight):
    bmi = weight / ((height / 100) ** 2)
    if bmi < 18.5:
        return 'thin'
    elif bmi < 25:
        return 'normal'
    return 'fat'


with open('data/bmi.csv', 'w', encoding='UTF-8') as file1:
    file1.write('height,weight,label\n')
    category = {'thin': 0, 'normal': 0, 'fat': 0}
    for i in range(30000):
        currentHeight = random.randint(140, 205)
        currentWeight = random.randint(40, 90)
        label = calculateBMI(currentHeight, currentWeight)
        category[label] += 1
        file1.write("%d,%d,%s\n" % (currentHeight, currentWeight, label))

print("generate OK, result={}".format(category))
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
import tensorflow as tf
import pandas as pd
import keras
from sklearn.preprocessing import LabelBinarizer
from keras import callbacks

csv1 = pd.read_csv("data/bmi.csv")
csv1['height'] = csv1['height'] / 200
csv1['weight'] = csv1['weight'] / 100
print(csv1[:10])
encoder = LabelBinarizer()
transformedLabel = encoder.fit_transform(csv1['label'])
print(csv1['label'][:10])
print(transformedLabel[:10])
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
import tensorflow as tf
import pandas as pd
import keras
from sklearn.preprocessing import LabelBinarizer
from keras import callbacks
from keras import layers, models

csv1 = pd.read_csv("data/bmi.csv")
csv1['height'] = csv1['height'] / 200
csv1['weight'] = csv1['weight'] / 100
print(csv1[:10])
encoder = LabelBinarizer()
transformedLabel = encoder.fit_transform(csv1['label'])
print(csv1['label'][:10])
print(transformedLabel[:10])

test_csv = csv1[25000:]
test_pat = test_csv[['weight', 'height']]
test_ans = transformedLabel[25000:]

train_csv = csv1[:25000]
train_pat = train_csv[['weight', 'height']]
train_ans = transformedLabel[:25000]

model = models.Sequential()
model.add(layers.Dense(10, activation='relu', input_shape=(2,)))
model.add(layers.Dense(3, activation='softmax'))
model.summary()
model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])
board = callbacks.TensorBoard(log_dir='logs/demo74')
model.fit(train_pat, train_ans, batch_size=50, epochs=100, verbose=1,
          validation_data=(test_pat, test_ans), callbacks=[board])
score = model.evaluate(test_pat, test_ans, verbose=0)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
import tensorflow as tf

imageSourceArray = tf.constant([1, 1, 1, 0, 0, 0] * 6, tf.float32)
print(imageSourceArray)
images = tf.reshape(imageSourceArray, [1, 6, 6, 1])
print(images[0, :, :, 0])
#filterSourceArray = tf.constant([1, 0, -1] * 3, tf.float32)
filterSourceArray = tf.constant([-1, 0, 1] * 3, tf.float32)
filter = tf.reshape(filterSourceArray, [3, 3, 1, 1])
print(filter[:, :, 0, 0])
conv = tf.nn.conv2d(images, filter, [1, 1, 1, 1], padding='VALID')
convResult = conv.numpy()
print(convResult.shape)
print(convResult[0, :, :, 0])
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
import tensorflow as tf

imageSourceArray = tf.constant([1, 1, 1, 0, 0, 0] * 6, tf.float32)

print(imageSourceArray)
images = tf.reshape(imageSourceArray, [1, 6, 6, 1])
images = tf.transpose(images, perm=[0, 2, 1, 3])
print(images[0, :, :, 0])
# filterSourceArray = tf.constant([1, 0, -1] * 3, tf.float32)
filterSourceArray = tf.constant([-1, 0, 1] * 3, tf.float32)
filter = tf.reshape(filterSourceArray, [3, 3, 1, 1])
filter = tf.transpose(filter, perm=[1, 0, 2, 3])
print(filter[:, :, 0, 0])
conv = tf.nn.conv2d(images, filter, [1, 1, 1, 1], padding='VALID')
convResult = conv.numpy()
print(convResult.shape)
print(convResult[0, :, :, 0])
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
demo76

import tensorflow as tf
from keras import layers, models
from keras.datasets import mnist
from keras.utils.np_utils import to_categorical

model = models.Sequential()
# model.add(layers.Conv2D(32, (3, 3), activation=tf.nn.relu, input_shape=(28, 28, 1), padding='same'))
model.add(layers.Conv2D(32, (3, 3), activation=tf.nn.relu, input_shape=(28, 28, 1), padding='valid'))
model.add(layers.MaxPooling2D((2, 2)))
# extract from feature map
model.add(layers.Conv2D(32, (3, 3), activation=tf.nn.relu, padding='valid'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(32, (3, 3), activation=tf.nn.relu, padding='valid'))
model.add(layers.Flatten())
model.add(layers.Dense(32, activation=tf.nn.relu))
model.add(layers.Dense(10, activation=tf.nn.softmax))
model.summary()
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
import tensorflow as tf
from keras import layers, models
from keras.datasets import mnist
from keras.utils.np_utils import to_categorical

model = models.Sequential()
# model.add(layers.Conv2D(32, (3, 3), activation=tf.nn.relu, input_shape=(28, 28, 1), padding='same'))
model.add(layers.Conv2D(32, (3, 3), activation=tf.nn.relu, input_shape=(28, 28, 1), padding='valid'))
model.add(layers.MaxPooling2D((2, 2)))
# extract from feature map
model.add(layers.Conv2D(32, (3, 3), activation=tf.nn.relu, padding='valid'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(32, (3, 3), activation=tf.nn.relu, padding='valid'))
model.add(layers.Flatten())
model.add(layers.Dense(32, activation=tf.nn.relu))
model.add(layers.Dense(10, activation=tf.nn.softmax))
model.summary()
(train_images, train_labels), (test_images, test_labels) = mnist.load_data()
train_images = train_images.reshape((60000, 28, 28, 1))
train_images = train_images.astype('float32') / 255
test_images = test_images.reshape((10000, 28, 28, 1))
test_images = test_images.astype('float32') / 255
train_labels = to_categorical(train_labels)
test_labels = to_categorical(test_labels)

model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])
model.fit(train_images, train_labels, epochs=5, batch_size=32)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
import tensorflow as tf
from keras import layers, models
from keras.datasets import mnist
from keras.utils.np_utils import to_categorical

model = models.Sequential()
# model.add(layers.Conv2D(32, (3, 3), activation=tf.nn.relu, input_shape=(28, 28, 1), padding='same'))
model.add(layers.Conv2D(32, (5, 5), activation=tf.nn.relu, input_shape=(28, 28, 1), padding='valid'))
#model.add(layers.Conv2D(32, (5, 5), activation=tf.nn.relu, input_shape=(1,28, 28), padding='valid'))
model.add(layers.MaxPooling2D((2, 2)))
# extract from feature map
model.add(layers.Conv2D(32, (5, 5), activation=tf.nn.relu, padding='valid'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(32, (5, 5), activation=tf.nn.relu, padding='same'))
model.add(layers.Flatten())
model.add(layers.Dense(32, activation=tf.nn.relu))
model.add(layers.Dense(10, activation=tf.nn.softmax))
model.summary()
(train_images, train_labels), (test_images, test_labels) = mnist.load_data()
train_images = train_images.reshape((60000, 28, 28, 1))
#train_images = train_images.reshape((60000, 1,28, 28))
train_images = train_images.astype('float32') / 255
test_images = test_images.reshape((10000, 28, 28, 1))
test_images = test_images.astype('float32') / 255
train_labels = to_categorical(train_labels)
test_labels = to_categorical(test_labels)

model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])
model.fit(train_images, train_labels, epochs=5, batch_size=32)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
import tensorflow as tf
from keras import layers, models
from keras.datasets import mnist
from keras.utils.np_utils import to_categorical

model = models.Sequential()
# model.add(layers.Conv2D(32, (3, 3), activation=tf.nn.relu, input_shape=(28, 28, 1), padding='same'))
model.add(layers.Conv2D(32, (5, 5), activation=tf.nn.relu, input_shape=(28, 28, 1), padding='valid'))
# model.add(layers.Conv2D(32, (5, 5), activation=tf.nn.relu, input_shape=(1,28, 28), padding='valid'))
model.add(layers.MaxPooling2D((2, 2)))
# extract from feature map
model.add(layers.Conv2D(32, (5, 5), activation=tf.nn.relu, padding='valid'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(32, (5, 5), activation=tf.nn.relu, padding='same'))
model.add(layers.Dropout(0.2))
model.add(layers.Flatten())
model.add(layers.Dense(32, activation=tf.nn.relu))
model.add(layers.Dense(10, activation=tf.nn.softmax))
model.summary()
(train_images, train_labels), (test_images, test_labels) = mnist.load_data()
train_images = train_images.reshape((60000, 28, 28, 1))
# train_images = train_images.reshape((60000, 1,28, 28))
train_images = train_images.astype('float32') / 255
test_images = test_images.reshape((10000, 28, 28, 1))
test_images = test_images.astype('float32') / 255
train_labels = to_categorical(train_labels)
test_labels = to_categorical(test_labels)

model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])
model.fit(train_images, train_labels, epochs=5, batch_size=32, validation_split=0.1)
~~~~~~~~~~~~~~~~~~~~~~~
import tensorflow as tf
from keras import layers, models
from keras.datasets import mnist
from keras.utils.np_utils import to_categorical

model = models.Sequential()
# model.add(layers.Conv2D(32, (3, 3), activation=tf.nn.relu, input_shape=(28, 28, 1), padding='same'))
model.add(layers.Conv2D(32, (5, 5), activation=tf.nn.relu, input_shape=(28, 28, 1), padding='valid'))
# model.add(layers.Conv2D(32, (5, 5), activation=tf.nn.relu, input_shape=(1,28, 28), padding='valid'))
model.add(layers.MaxPooling2D((2, 2)))
# extract from feature map
model.add(layers.Conv2D(32, (5, 5), activation=tf.nn.relu, padding='valid'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(32, (5, 5), activation=tf.nn.relu, padding='same'))
model.add(layers.Dropout(0.2))
model.add(layers.Flatten())
model.add(layers.Dense(32, activation=tf.nn.relu))
model.add(layers.Dense(10, activation=tf.nn.softmax))
model.summary()
(train_images, train_labels), (test_images, test_labels) = mnist.load_data()
train_images = train_images.reshape((60000, 28, 28, 1))
# train_images = train_images.reshape((60000, 1,28, 28))
train_images = train_images.astype('float32') / 255
test_images = test_images.reshape((10000, 28, 28, 1))
test_images = test_images.astype('float32') / 255
train_labels = to_categorical(train_labels)
test_labels = to_categorical(test_labels)

model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])
model.fit(train_images, train_labels, epochs=5, batch_size=32, validation_split=0.1)
